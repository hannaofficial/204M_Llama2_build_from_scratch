# 204M_Llama2_build_from_scratch
This is llama2 model code build from scratch using pytorch. 204M parameter. I have write the code to train the model on 1.5 Billion tokens but you can change the tokens as per your wish.

There are some code to update
* Include helloswag inside training loop
*  saving checkpoint of the model after certain loop
